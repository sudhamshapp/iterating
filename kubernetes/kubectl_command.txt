kubectl get pods
kubectl get deploy
kubectl describe pod <name-of-the-pod>
kubectl describe deployment <name-of-the-deployment>
kubectl apply -f <file.yml>
kubectl delete -f <file.yml>
kubectl edit deploy <deployemnt-name> - edits the manifest file on the fly
kubectl get pods -w (the command waits for the status of the pod)
kubectl get pods -o wide (it fetches the ip respective ip address of the as well)
kubectl delete -f . (deletes all the manifests in the current directory in a single go)
kubectl get service
kubectl describe service <service-name> gives the stuff, when we speciifcally check for Endpoints attribute, it has the pod ips
kubectl get nodes -o wide gives the ec2instance/workernodes public and priivate ips

This complete setup is for nginx-ingress controller
kubectl create namespace ingress-nginx
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.1/deploy/static/provider/cloud/deploy.yaml
kubectl get all -n ingress-nginx
create the deployemnts of nginx and httpd and the deployment of ingress resource - this spits classic load balancer where we can nginx/httpd on single Loadbalancer url based on the path

ingress resource enables the communication b/w ingress controller and actual deployments
kubectl get ingress
kubectl get service -n ingress-nginx

kubectl get cm
kubectl describe cm <nameoftheconfigmap>
kubectl get sc

kubectl exec <podname> <command>
kubectl exec mongo-express-7f7c6dff4-db7pv env

kubectl get namespaces
kubectl get all -n kube-system
kubectl create namespace mars
kubectl create ns mars
kubectl get all --namespace mars
kubectl get all -n mars


kubectl get pv
kubectl get pvc

Headless service: won't have the ip, it only works on the DNS entries

kubectl get daemonset

kubectl get jobs

kubectl logs <podname>

kubectl get all -n kube-system - we have metric server in it which is helpful for hpa and cluster autoscaler

kubectl get hpa

kubectl get limitrange

kubectl describe limitrange <limitrangename>

if we configure the request and limit at namespace level it is stated as Resource Quota

if we configure the request and limit at pod level it is stated as limit range